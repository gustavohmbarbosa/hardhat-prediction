# üìä O que significam mAP\@0.5 e mAP\@0.5:0.95?

### 1. AP (Average Precision)

* Em detec√ß√£o de objetos, voc√™ tem **precis√£o** e **revoca√ß√£o (recall)**:

  * **Precis√£o** = TP / (TP + FP) ‚Üí dos que previ, quantos est√£o certos?
  * **Recall** = TP / (TP + FN) ‚Üí dos objetos reais, quantos detectei?
* Se voc√™ varia o limiar de confian√ßa do modelo (score m√≠nimo para considerar uma detec√ß√£o), obt√©m diferentes pontos de (precis√£o, recall).
* A **curva precis√£o‚Äìrecall (PR curve)** √© gerada.
* **AP** = √°rea sob essa curva (quanto mais perto de 1.0, melhor).

---

### 2. IoU (Intersection over Union)

* Para dizer se uma previs√£o acerta um objeto, usamos **IoU**:

  $$
  IoU = \frac{√Årea\_Interse√ß√£o}{√Årea\_Uni√£o}
  $$
* Se IoU ‚â• um limiar (threshold), contamos como **TP**; sen√£o, **FP**.

---

### 3. mAP (mean Average Precision)

* Em datasets com v√°rias classes, calcula-se o AP de cada classe e faz-se a m√©dia: **mAP**.
* No seu caso (s√≥ capacete), mAP ‚âà AP da classe 0.

---

### 4. Diferen√ßa entre @0.5 e @0.5:0.95

* **mAP\@0.5**: s√≥ considera IoU = 0.5 (50%).

  * Uma detec√ß√£o √© ‚Äúcerta‚Äù se sobrep√µe pelo menos metade do objeto.
  * M√©trica **mais permissiva**.
* **mAP\@0.5:0.95**: √© a m√©trica oficial do COCO.

  * Calcula o AP em **10 thresholds**: IoU = 0.5, 0.55, 0.6, ‚Ä¶, 0.95.
  * Faz a m√©dia de todos.
  * √â **mais r√≠gida**: exige n√£o s√≥ encontrar o objeto, mas tamb√©m localiz√°-lo com alta precis√£o.
  * Normalmente o valor √© bem mais baixo que @0.5.

---

# üìê Como s√£o calculados na pr√°tica

1. Para cada IoU threshold:

   * Ordena as detec√ß√µes por confian√ßa.
   * Marca TP/FP com base no IoU.
   * Constr√≥i a curva P‚ÄìR.
   * Calcula a √°rea sob a curva (AP).
2. Para mAP:

   * Faz a m√©dia dos APs de todas as classes (no seu caso, s√≥ uma).
3. Para mAP\@0.5:0.95:

   * Repete o processo em todos os thresholds 0.5‚Äì0.95 (passo 0.05).
   * Faz a m√©dia final.

---

# üîé Como interpretar

* **mAP\@0.5** alto (ex.: 0.88) ‚Üí o modelo **encontra bem** os capacetes, mesmo que a caixa n√£o seja perfeita.
* **mAP\@0.5:0.95** mais baixo (ex.: 0.58) ‚Üí o modelo tem dificuldade em localizar com exatid√£o (as caixas podem estar frouxas ou deslocadas).
* **Gap grande** entre os dois ‚Üí indica que o modelo detecta mas n√£o posiciona as caixas com precis√£o.
* **Gap pequeno** ‚Üí indica detec√ß√µes bem localizadas.

---

üìå exemplo da sua tabela:

```
baseline_v8n_320 ‚Üí mAP@0.5 = 0.8879, mAP@0.5:0.95 = 0.5803
```

üëâ O modelo encontra quase 89% dos capacetes de forma aceit√°vel, mas s√≥ \~58% ficam com bounding box bem justa (alta qualidade de localiza√ß√£o).
