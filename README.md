# Helmet YOLO Reducer

Este projeto tem como objetivo **treinar** e, em seguida, **reduzir** o tamanho de um modelo YOLO para detec√ß√£o de **capacete** (1 classe).

## ‚öôÔ∏è Metodologia

### 0) Preparar o dataset | `prepare_helmet_dataset.py`

```bash
python prepare_helmet_dataset.py
```

* Faz o download do dataset do Kaggle (se j√° n√£o existir em `dataset/`).
* Aplica a filtragem dos r√≥tulos, mantendo **apenas a classe 0 (capacete)**.
* Gera uma estrutura de pastas no formato YOLO:

  ```
  dataset/
    images/{train,val,test}
    labels/{train,val,test}
  ```

>‚ö†Ô∏è **Nota**: √© necess√°rio ter as credenciais do Kaggle configuradas (`kaggle.json`). Saiba mais em https://www.kaggle.com/docs/api#authentication.

### 1) Treino baseline | `train_baseline.py`

```bash
python train_baseline.py
```

* Treina o **YOLOv8n (nano)** pr√©-treinado no COCO.
* Usa hiperpar√¢metros fixos definidos no c√≥digo (ex.: `imgsz=320`, `epochs=60`, `batch=16`).
* Serve como **refer√™ncia** para compara√ß√£o com vers√µes reduzidas.

### 2) Treino reduzido | `train_reduced.py`

```bash
python train_reduced.py
```

* Treina uma arquitetura **modificada** a partir de um `.yaml` em `models/` (ex.: `yolov8n_min.yaml`).
* O `.yaml` usa multiplicadores menores de **depth** e **width**, reduzindo:

  * **Par√¢metros (M)**
  * **FLOPs (G)**
  * **Tamanho do arquivo**
* Objetivo: encontrar um ponto de equil√≠brio entre **tamanho menor** e **mAP aceit√°vel**.

### 3) Poda do modelo (descartado) | `prune_and_finetune.py`

> Objetivo: **reduzir ainda mais** o tamanho/complexidade do modelo **depois** do treino, removendo canais pouco importantes (**structured channel pruning**) e, opcionalmente, fazer um **fine-tune** curto para recuperar mAP.

#### O que o script faz

1. **Carrega** um checkpoint treinado (`best.pt`) do Ultralytics YOLO.
2. **Calcula import√¢ncia** dos canais (L1/Magnitude) e seleciona **apenas** `Conv2d` com `groups==1` (evita depthwise/DFL/Detect).
3. **Tenta podar estruturalmente** (remover canais do grafo, n√£o s√≥ zerar pesos).
4. **Salva** o resultado
5. (Opcional) **Fine-tune** r√°pido no modelo podado para **recuperar a acur√°cia**.

> Nota: em arquiteturas com **atalhos/concats** (como YOLOv8 com blocos C2f e m√∫ltiplos heads), a poda estrutural √© **mais restrita**. Se o grafo n√£o puder ser ajustado com seguran√ßa, o script evita cortes perigosos (isso pode resultar em ‚Äúsem mudan√ßa de Params/FLOPs‚Äù). A alternativa mais robusta e simples √© **reduzir a arquitetura pelo YAML** (width/depth), e usar **quantiza√ß√£o** para diminuir arquivo/lat√™ncia.

#### Uso

```bash
# depend√™ncias
pip install torch-pruning ultralytics thop onnx onnxruntime

# execu√ß√£o
python prune_and_finetune.py \
  --weights runs_train/<seu_run>/weights/best.pt \
  --data hardhat.yaml \
  --imgsz 320 \
  --epochs 30 \        # 0 = n√£o faz fine-tune
  --batch 16 \
  --sparsity 0.35 \    # 0.2~0.35 = moderado; >0.5 = agressivo
  --device cuda:0
```

##### Argumentos principais

* `--weights`: checkpoint treinado a ser podado (ex.: `best.pt`).
* `--data`: YAML do dataset (ex.: `hardhat.yaml`) ‚Äî usado no fine-tune.
* `--imgsz`: tamanho de entrada para tra√ßar o grafo.
* `--epochs`: √©pocas de **fine-tune p√≥s-poda** (0 para pular).
* `--batch`: batch size do fine-tune.
* `--sparsity`: **propor√ß√£o global de canais a remover** (0.0‚Äì0.9).
* `--device`: `cuda:0` para GPU, ou `cpu`.

##### Sa√≠das esperadas

* `pruned_full.pt` ‚Üí **nn.Module** podado (estrutura menor).
* `pruned.onnx` ‚Üí export estruturado (se `onnx` instalado).
* Novo run em `runs_prune/<exp>/` se `--epochs > 0` (fine-tune), com `weights/best.pt` e m√©tricas.

#### Como avaliar

* Rode `python summarize_runs.py` para comparar **Params, FLOPs, Size, Latency e mAP** antes √ó depois.
* Se **Params/FLOPs n√£o mudarem**, a poda **n√£o foi estruturalmente aplicada** naquela topologia


### 4) Resumir resultados | `summarize_runs.py`

```bash
python summarize_runs.py
```

* Coleta automaticamente os resultados em `runs_train/*` e `runs_prune/*`.
* Gera um relat√≥rio `.csv` e `.md` com m√©tricas dos modelos.

Exemplo:
| Kind   | Run                           | Stage        | Model            |   ImgSize |   Epochs |   Batch | File                                          |   Size (MB) |   mAP@0.5 |   mAP@0.5:0.95 |   Train Time (min) |   Params (M) |   FLOPs (G) |   Latency (ms) |
|:-------|:------------------------------|:-------------|:-----------------|----------:|---------:|--------:|:----------------------------------------------|------------:|----------:|---------------:|-------------------:|-------------:|------------:|---------------:|
| run    | runs_train\reduced_min_320_v2 | reduced_arch | yolov8n_min.yaml |       320 |      100 |      32 | runs_train\reduced_min_320_v2\weights\best.pt |       3.109 |    0.861  |         0.5402 |              211.4 |       1.5387 |      0.5748 |          6.21  |
| run    | runs_train\reduced_min_320    | reduced_arch | yolov8n_min.yaml |       320 |       10 |      16 | runs_train\reduced_min_320\weights\best.pt    |       3.603 |    0.7638 |         0.4493 |               18.7 |       1.7992 |      0.6469 |          6.569 |
| run    | runs_train\baseline_v8n_320   |              | yolov8n.pt       |       320 |       60 |      16 | runs_train\baseline_v8n_320\weights\best.pt   |       5.923 |    0.8879 |         0.5803 |               89.7 |       3.011  |      1.0243 |          6.965 |

## Explica√ß√£o das colunas

* **Kind** ‚Üí tipo de entrada (`run` = treino, `pruned_ckpt` = modelo podado sem fine-tune).
* **Run** ‚Üí diret√≥rio do experimento.
* **Stage** ‚Üí est√°gio do processo (baseline, reduced\_arch, prune, etc).
* **Model** ‚Üí qual YAML ou checkpoint foi usado.
* **ImgSize** ‚Üí resolu√ß√£o de entrada (pixels).
* **Epochs** ‚Üí n√∫mero de √©pocas de treino.
* **Batch** ‚Üí tamanho do batch.
* **File** ‚Üí caminho para o `best.pt`.
* **Size (MB)** ‚Üí tamanho do arquivo em disco.
* **mAP\@0.5** ‚Üí m√©dia da precis√£o m√©dia com IoU=0.5 (permissivo).
* **mAP\@0.5:0.95** ‚Üí m√©trica oficial COCO (IoU=0.5:0.95, mais rigorosa).
* **Train Time (min)** ‚Üí dura√ß√£o estimada do treino.
* **Params (M)** ‚Üí n√∫mero de par√¢metros (em milh√µes).
* **FLOPs (G)** ‚Üí custo computacional (em bilh√µes de opera√ß√µes).
* **Latency (ms)** ‚Üí tempo m√©dio de infer√™ncia de 1 imagem (ms).

## üîó √ötil

* [Descri√ß√£o de par√¢metros YOLO](./YOLO.md)
* [Script de verifica√ß√£o GPU/CUDA](./verify-cuda.py):

  ```bash
  python verify-cuda.py
  ```
